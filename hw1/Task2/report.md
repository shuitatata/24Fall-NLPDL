# Task 2
## 词典构建
使用`jieba`分词，将训练集中的文本进行分词，并整理为词典。
经测试，训练集中85%的词在该词典中，其余的词用\<unk>表示。

## 模型结构
按照论文中的描述，我构建了一个卷积神经网络。这个网络的输入是token的序列，首先进行embedding，然后同时进行多次卷积与池化操作，将结果拼接在一起，最后通过全连接层和softmax归一化输出分类的结果。
## 模型参数
词向量维度为256。
卷积核的大小分别为2、3、4、5，每个卷积核输出的通道数为128。
drupout概率为0.4，学习率为0.001，batch size为16。
模型训练了5个epoch
## 模型效果
在训练集上的准确率达到了99.0%，在验证集上的准确率是75.9%，在测试集上的准确率达到80.1%。

![image](result.png)